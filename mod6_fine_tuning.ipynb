{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6 - Fine-tuning ResNet toward plankton data\n",
    "\n",
    "We have seen that a neural network that was trained on a completely plankton-unrelated dataset (like ImageNet) still produces features that allow the classification of plankton data.\n",
    "Now, we can go a step further and *fine-tune* such a network to do plankton classification.\n",
    "This is akin to teaching a person without prior oceanographic experience how to recognize different types of fish, assuming that they are able to recognize other kinds of objects.\n",
    "\n",
    "In practice, CNNs are almost always fine-tuned (and not trained from scratch) for convergence reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import RandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "from utilities.display_utils import imshow_tensor, make_confmat\n",
    "from utilities.split import stratified_random_split\n",
    "\n",
    "TRAINING_PATH = \"../Data/pogo_bioobs_2019/ZooScan/train\"\n",
    "VALIDATION_PATH = \"../Data/pogo_bioobs_2019/ZooScan/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and transformation\n",
    "\n",
    "Image datasets can conveniently loaded with [`torchvision.datasets.ImageFolder`](https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder).\n",
    "It assumes one folder for each class where the images are located.\n",
    "\n",
    "CNNs have a fixed input size. ResNets happen to be trained with 224x244 images. \n",
    "Therefore, we need to make sure that each image has the correct dimensions.\n",
    "`ImageFolder` has a `transform` parameter for that.\n",
    "After resizing, the images need to be converted to a PyTorch [`Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor).\n",
    "\n",
    "We will use the training set for the training the network and the validation set for the evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    # Resize every image to a 224x244 square\n",
    "    Resize((224,224)),\n",
    "    # Convert to a tensor that PyTorch can work with\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Images are located at at {dataset_path}/{class_name}/{objid}.jpg\n",
    "dataset_train = ImageFolder(TRAINING_PATH, transform)\n",
    "dataset_val = ImageFolder(TRAINING_PATH, transform)\n",
    "\n",
    "# Make sure that the class names are identical\n",
    "assert dataset_train.classes == dataset_val.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tensor and the label of the first example\n",
    "tensor, label = dataset_train[0]\n",
    "\n",
    "print(\"Class: {:d} ({})\".format(label, dataset_train.classes[label]))\n",
    "imshow_tensor(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the model\n",
    "\n",
    "We start with a pre-trained ResNet18 model.\n",
    "It was initially trained on ImageNet which happens to contain 1000 classes. However, our plankton dataset contains XXX classes. Therefore, we have to reset the classifier layer to the correct number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# get the number of features that are input to the fully connected layer\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "# reset the fully connect layer\n",
    "model.fc = nn.Linear(num_ftrs, len(dataset_train.classes))\n",
    "\n",
    "# Transfer model to GPU\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the optimizer\n",
    "\n",
    "We will train the network using [Stochastic Gradient Descend (SDG)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).\n",
    "In each iteration, the network parameters are updated in order to minimize a training criterion, in our case the [Cross Entropy](https://en.wikipedia.org/wiki/Cross_entropy) Loss.\n",
    "The better the predictions, the smaller the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128,\n",
    "                                           shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate training mode\n",
    "model.train()\n",
    "\n",
    "# Train for 5 epochs\n",
    "for epoch in tnrange(5, desc=\"Epoch\"):\n",
    "    # tqdm_notebook displays a nice progress bar\n",
    "    with tqdm_notebook(loader_train, desc=\"Training Epoch #{:d}\".format(epoch + 1)) as t:\n",
    "        for inputs, labels in t:\n",
    "            # Copy data to GPU\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            t.set_postfix(loss=loss.item())\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Let's see how well our model performs.\n",
    "\n",
    "First, display some examplary images together with their ground-truth and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Activate evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# A data loader for the validation set with a batch size of 4 for demonstration purposes\n",
    "loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=4, shuffle=True)\n",
    "\n",
    "# Extract one batch\n",
    "images, labels = next(iter(loader_val))\n",
    "\n",
    "# Show images of the batch\n",
    "imshow_tensor(torchvision.utils.make_grid(images))\n",
    "print('Ground truth:', ', '.join('%5s' % dataset_val.classes[labels[j]] for j in range(4)))\n",
    "\n",
    "# Run the batch through the model\n",
    "outputs = model(images.cuda())\n",
    "\n",
    "# Collect the predicted classes\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted:', ', '.join('%5s' % dataset_val.classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a thorough evaluation of the whole dataset. In order to do that, we need to run the whole validation set through the network and record the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = []\n",
    "labels_predicted = []\n",
    "\n",
    "# Validation data loader with a reasonable batch size\n",
    "loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128, num_workers=4, shuffle=True)\n",
    "\n",
    "# Activate evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# We don't need to calculate gradients\n",
    "with torch.no_grad():\n",
    "    with tqdm_notebook(loader_val, desc=\"Evaluating\") as t:\n",
    "        for inputs_batch, labels_batch in t:\n",
    "            # Copy data to GPU\n",
    "            inputs_batch = inputs_batch.cuda()\n",
    "\n",
    "            outputs = model(inputs_batch)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            labels_true.extend(labels_batch.tolist())\n",
    "            labels_predicted.extend(predicted.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(labels_true, labels_predicted)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(labels_true,\n",
    "                            labels_predicted,\n",
    "                            labels=np.arange(len(dataset_val.classes)),\n",
    "                            target_names=dataset_val.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you know what these scores are?\n",
    "Make yourself familiar with [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) and the [F-Score](https://en.wikipedia.org/wiki/F1_score). These are important metrics for the evaluation of a classifier.\n",
    "\n",
    "You may notice that classes with a larger support (number of examples) tend to get higher scores. Can you guess why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "make_confmat(labels_true, labels_predicted, acc, labels=dataset_val.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you see a diagonal of true predictions. You may also notice vertical stripes that occur if a wide range of different objects is classified as the same class. This often happens in datasets with a skewed class distribtion where a few classes contain most of the objects. In this case, the classifier learns that it is a relative save bet to predict these majority classes most of the time. Module 7 will take care of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "- Apply this notebook to the SPC dataset.\n",
    "- Compare the results to the previous classifiers.\n",
    "- What happens if you use a randomly initialized network (`model = models.resnet18(pretrained=False)`)?\n",
    "- Try different [transformations](https://pytorch.org/docs/stable/torchvision/transforms.html).\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this module, you learned how to use a folder of images to fine-tune a model in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Visualization of the feature space\n",
    "\n",
    "How are the classes distributed in the feature space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the model but remove the last layer\n",
    "feat_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "# We don't need to calculate gradients\n",
    "with torch.no_grad():\n",
    "    with tqdm_notebook(loader_val, desc=\"Evaluating\") as t:\n",
    "        for input_batch, label_batch in t:\n",
    "            # Copy input batch to GPU\n",
    "            input_batch = input_batch.cuda()\n",
    "\n",
    "            features_batch = feat_extractor(input_batch)\n",
    "            \n",
    "            features.extend(features_batch.cpu().numpy())\n",
    "            labels.extend(label_batch.cpu().numpy())\n",
    "            \n",
    "features = np.array(features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We project the features from 512 dimensions to 2 dimensions using [t-SNE](https://lvdmaaten.github.io/tsne/). This will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE()\n",
    "features_2d = tsne.fit_transform(np.squeeze(features)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scat = ax.scatter(features_2d[:,0], features_2d[:,1], c=labels[:1000])\n",
    "cbar = fig.colorbar(scat)\n",
    "cbar.set_ticks(np.arange(len(dataset_val.classes)))\n",
    "cbar.set_ticklabels(dataset_val.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, the different classes build clusters in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
