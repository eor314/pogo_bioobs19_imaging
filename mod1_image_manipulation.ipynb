{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 - Image Manipulation\n",
    "\n",
    "To run all but the most basic commands in Python we need to import packages that contain most of the functionality.\n",
    "Here we will introduce a few that are useful for image manipulation:\n",
    "\n",
    "1. numpy is a matrix manipulation suite. It is akin to the basic processing package availble in MATLAB. \n",
    "2. matplotlib is a graphics toolbox for python. \n",
    "3. cv2 is OpenCV, an open-source computer vision library. OpenCV has lots of useful functions to manipulate and analyze images. We will make ample use of the tools in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the packages are imported into the workspace. We can now use them inline below. \n",
    "\n",
    "First we will grab an image to play with. OpenCV has a really easy routine for it. After, we will display it with plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file path of the image in the directory\n",
    "# glob is a library that impliments pathname pattern expansion in python. os is an operating system navigation package\n",
    "\n",
    "# this command creates a list of all files with the letters SPC as the first characters in the current working directory. \n",
    "ptf = glob.glob(os.path.join(os.getcwd(), 'SPC*'))\n",
    "print(ptf[0])\n",
    "\n",
    "# We will grab the first item in the list\n",
    "img = cv2.imread(ptf[0])\n",
    "\n",
    "# now display it so we can see what we are working with\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image manipulation and transformation\n",
    "\n",
    "Before getting into the topic of edge detection and region finding, we will practice a few basic image manipulations. Most of these transformations are implemented for us in OpenCV. For now, the routines are mostly being explored to gain some intuition for working with images in Python. But these routines will eventually be useful for *data augmentation* for running deep nets.\n",
    "\n",
    "First, we will check the data type.\n",
    "A lot of errors in OpenCV and other image processing libraries occur because of type errors.\n",
    "The data type is a property of the image and can be accessed with *img.dtype*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many datatypes that could be useful and images are often convereted from type-to-type depending on the operation being preformed. *uint8* stands for \"Unsigned integer\" and is in the range of 0 to 255. 0 = black, 255 = white. \n",
    "\n",
    "Numpy matrices also make the min and max values easy to access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the min and max values\n",
    "print(\"The max pixel value is: \", str(img.max()))\n",
    "print(\"The min pixel value is: \", str(img.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixels and values\n",
    "Next, we can start messing with images by referencing particular pixels via their index. Most color images are treated as a 3-D matrix consisting of rows, columns and color chanels. \n",
    "\n",
    "The images provided for this tutorial from the Scripps Plankton Camera have three color channels. In OpenCV, images are loaded with colors in BLUE, GREEN, RED order.\n",
    "\n",
    "To view an image in RGB convert it using cv2.cvtColor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that in Python, indicies are referenced to 0. This is different from R and MATLAB that have all indicies starting at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the dimensions of the image\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the color values at a particular pixel.\n",
    "px_val = img[500, 800, :]\n",
    "print(\"[B, G, R] values: \" + str(px_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just look at the RED value\n",
    "red_val = img[500, 800, 2]\n",
    "print(\"The red channel value: \" + str(red_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to examine a single color channel from our image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the channel to a new array\n",
    "img_red = img[:, :, 2]\n",
    "\n",
    "# now see what it looks like\n",
    "plt.imshow(img_red, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, it is often convenient to convert a color image to gray scale. Again, OpenCV has a built in fuction for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert to gray scale with OpenCV\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# give it a look\n",
    "plt.imshow(img_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both the *cv2.cvtColor* and *plt.imshow* each used optional arguements. For the gray scale converstion, the optional arguement is telling OpenCV how to interpolate the colors. Likewise, in the figure display, matplotlib needs the appropriate colorscale.\n",
    "\n",
    "Lastly, sometimes it is useful to select a subsection of an image. This might come in handy for selecting a Region Of Interest from a larger frame or data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a small chunk of the gray sacle frame\n",
    "img_sub = img_gray[400:800, 400:800]\n",
    "\n",
    "# check it out\n",
    "plt.imshow(img_sub, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice\n",
    "Grab a subregion of the original image with all the color channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subregion of color image\n",
    "clr_sub = img[400:800, 400:800, :]\n",
    "\n",
    "# plot it\n",
    "plt.imshow(clr_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now convert your subregion to gray scale, check the min and max pixel values, and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make your subregion gray scale\n",
    "clr_sub_gray = cv2.cvtColor(clr_sub, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# print out the min and max values\n",
    "print(\"The max pixel value is: \", str(clr_sub_gray.max()))\n",
    "print(\"The min pixel value is: \", str(clr_sub_gray.min()))\n",
    "\n",
    "# plot it\n",
    "plt.imshow(clr_sub_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms\n",
    "### Resizing\n",
    "The most common type of transform is resizing. OpenCV has a builtin function to do this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the original image to make it half as large\n",
    "\n",
    "# first save grab the dimensions for use in the function\n",
    "hh, ww = img.shape[:2]\n",
    "\n",
    "# then halve the values\n",
    "new_hh = hh/2\n",
    "new_ww = ww/2\n",
    "\n",
    "# print them out\n",
    "print(\"The new height will be: \", str(new_hh))\n",
    "print(\"The new width will be: \", str(new_ww))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these numbers are float (ie decimals). OpenCV requires that indices are integers. We use Python built-in conversion command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the second arguement in resize tells it what to do with height\n",
    "img_resize = cv2.resize(img, (int(ww/2), int(hh/2)))\n",
    "\n",
    "# plot it\n",
    "plt.imshow(img_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that the image resize function **does not** preserve the aspect of the image. This becomes important when running deep nets that require input images to have the same dimensions. After transformation, the input data will not retain aspect information that may be important for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force the original images to be a square matrix\n",
    "img_square = cv2.resize(img, (512, 512))\n",
    "\n",
    "# plot it\n",
    "plt.imshow(img_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect may or may not be important depending on your application.\n",
    "\n",
    "### Image warping\n",
    "Most transforms in OpenCV are implimented as either an affine or perpective warps. Affine transformations preserve parallelism between the original and modified image -- a set of parallel lines in the original image will remain parallel in the new one. Perpective transforms only preserve straight lines between the original and transformed images.\n",
    "\n",
    "#### Affine transformations set up\n",
    "Use these transformations for things like translating, rotating, or shearing the image. All of these transformations require generating a transformation matrix that dictate the mathematical instructions for the warping.   \n",
    "\n",
    "To translate an image 50 pixels down and 200 pixels to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the translation matrix. The desired amount of shift is placed in the final column of the matrix\n",
    "mm = np.float32([[1, 0, 200], [0, 1, 50]])\n",
    "print(\"Translation matrix: \")\n",
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the warping wiht warpAffine()\n",
    "img_translate = cv2.warpAffine(img, mm, (ww, hh))\n",
    "\n",
    "# plot it\n",
    "plt.imshow(img_translate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotating the image about a point requires a different matrix that OpenCV will set up for you with *getRotationMatrix2D*. The first argument defines the point about which to do the rotations. For example, to rotate the image 45 degrees about the center:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rotation matrix\n",
    "mm = cv2.getRotationMatrix2D((ww/2, hh/2), 45, 1)\n",
    "\n",
    "# warp it\n",
    "img_rot = cv2.warpAffine(img, mm, (ww, hh))\n",
    "\n",
    "# plot it\n",
    "plt.imshow(img_rot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perspective transforms\n",
    "Perspective warping is good for mimicing the effect of zooming in or out of an image. To produce the behavior, you need to provide *getPerspectiveTransform* with two sets of four points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_pts = np.float32([[50, 50], [52, 800], [1500, 42], [1550, 750]])\n",
    "dst_pts = np.float32([[0, 0], [0, 750], [1450, 0], [1450, 750]])\n",
    "\n",
    "mm = cv2.getPerspectiveTransform(orig_pts, dst_pts)\n",
    "\n",
    "img_pres = cv2.warpPerspective(img, mm, (1450, 750))\n",
    "\n",
    "plt.imshow(img_pres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the test image (rotate it 180 degrees about the middle)\n",
    "mm = cv2.getRotationMatrix2D((ww/2, hh/2), 180, 1)\n",
    "\n",
    "# warp it\n",
    "img_flip = cv2.warpAffine(img, mm, (ww, hh))\n",
    "\n",
    "# plot it\n",
    "plt.imshow(img_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now translate the rotated image up 50 pixels and 100 to the left\n",
    "mm = np.float32([[1, 0, -100], [0, 1, -50]])\n",
    "\n",
    "img_flip_tran = cv2.warpAffine(img_flip, mm, (ww, hh))\n",
    "\n",
    "# plot it\n",
    "plt.imshow(img_flip_tran)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
